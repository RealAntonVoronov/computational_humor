{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RealAntonVoronov/computational_humour/blob/master/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmRO5gDi6wIJ",
        "colab_type": "text"
      },
      "source": [
        "# Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-MEcLwT-4nd",
        "colab_type": "text"
      },
      "source": [
        "## 0. Load the data. \n",
        "\n",
        "Так как данных предоставленных орагнизаторами явно недостаточно для того чтобы обучить полноценную языковую модель, для каждого из 5 языков были загружены параллельные корпуса субтитров. (http://opus.nlpl.eu/OpenSubtitles-v2016.php) Данные можно также найти на сервере nlp1 в папке `voronov/data/OpenSubtitles`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM-7FZ_l6nhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d5eba5c-754b-491b-bb6a-44300da18014"
      },
      "source": [
        "# this is for colab skip if you don't need to connect to drive)\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "course = 'en_pt'\n",
        "path_to_corpora = os.path.join('/content/gdrive/My Drive/data/work/Panchenko/corpora/OpenSubtitles/', course)\n",
        "os.chdir(path_to_corpora) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFLwpfLr--JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/moses/en-ko.txt.zip\n",
        "!unzip  'download.php?f=OpenSubtitles%2Fv2016%2Fmoses%2Fen-ko.txt.zip' && rm 'download.php?f=OpenSubtitles%2Fv2016%2Fmoses%2Fen-ko.txt.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8tSrMbx_hSN",
        "colab_type": "text"
      },
      "source": [
        "Для некоторых языков в корпусе OpenSubtitles представлено слишком много пар предложений. Нам столько не нужно. Возьмём 2 миллиона (если можно), после предобработки это число сильно уменьшится. В конце из оставшихся предложений ещё 5 тысяч нужны будут для валидационной части скрипта openNMT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSkLQpzC_cQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n 2000000 'OpenSubtitles.en-pt.en' > 'subs_2m.en'\n",
        "!head -n 2000000 'OpenSubtitles.en-pt.pt' > 'subs_2m.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSntEkjkAP6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "cb45cc9d-1d17-4c3d-b1b0-e68c1f3ea0e9"
      },
      "source": [
        "!head subs_2m.en"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amanonce said, \"When you make a friend, you take on a responsibility.\"\n",
            "That describes my friend, Danny Barrett.\n",
            "When he invited me to lunch I should have known there'd be strings attached.\n",
            "Excuse me, guys.\n",
            "Sorry.\n",
            "Sure.\n",
            "Go ahead.\n",
            "MacGyver, you're just in time.\n",
            "For what?\n",
            "You said lunch.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bkCdZZ7Dn89",
        "colab_type": "text"
      },
      "source": [
        "## 1. Find equal lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWzha4d7Bfv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_lines = open('subs_2m.en').readlines()\n",
        "pt_lines = open('subs_2m.pt').readlines()\n",
        "with  open('subs_2m.pt', 'w') as pt, open('subs_2m.en', 'w') as en:\n",
        "    for i in range(len(en_lines)):\n",
        "        if en_lines[i] != pt_lines[i]:\n",
        "            en.writelines(en_lines[i])\n",
        "            pt.writelines(pt_lines[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs2jBNykDO7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3f72354-f031-4a51-c75d-6f21db011e22"
      },
      "source": [
        "!wc -l subs_2m.pt"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1973603 subs_2m.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3uO92M21u3c",
        "colab_type": "text"
      },
      "source": [
        "## 2. Remove examples where source or target contains multiple sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taRWv2yrzEda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5bd3ccdc-68dd-4a92-9f83-ef0a26fa7b7f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "src_lines = open('subs_2m.en').readlines()\n",
        "tgt_lines = open('subs_2m.pt').readlines()\n",
        "n = len(src_lines)\n",
        "with open('subs_2m.en', 'w') as src, open('subs_2m.pt', 'w') as tgt:\n",
        "    for i in range(n):\n",
        "        src_line = src_lines[i].strip()\n",
        "        n_src_sentences = len(sent_tokenize(src_line))\n",
        "        tgt_line = tgt_lines[i].strip()\n",
        "        n_tgt_sentences = len(sent_tokenize(tgt_line))\n",
        "        if n_src_sentences==1 and n_tgt_sentences==1:\n",
        "            src.writelines(src_lines[i])\n",
        "            tgt.writelines(tgt_lines[i])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_B4eBwp2ZU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "85045816-fc45-4958-c413-2b53bcc32ffa"
      },
      "source": [
        "!wc -l subs_2m.pt\n",
        "!wc -l subs_2m.en"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "964630 subs_2m.pt\n",
            "964630 subs_2m.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reLoOrLoDxwG",
        "colab_type": "text"
      },
      "source": [
        "## 3. Remove examples where actual language differs from claimed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7LK3qEJER7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "7754e8a9-00b8-4576-e2c3-9a221dbe93b4"
      },
      "source": [
        "!pip install langid"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langid\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/4c/0fb7d900d3b0b9c8703be316fbddffecdab23c64e1b46c7a83561d78bd43/langid-1.1.6.tar.gz (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from langid) (1.18.2)\n",
            "Building wheels for collected packages: langid\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-cp36-none-any.whl size=1941190 sha256=5025d92624f1228df1019e9c73ea8872dfef55c198919c0369a2803510d4c842\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/bc/61/50a93be85d1afe9436c3dc61f38da8ad7b637a38af4824e86e\n",
            "Successfully built langid\n",
            "Installing collected packages: langid\n",
            "Successfully installed langid-1.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m5kpAeN_N8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!langid --line -n < subs_2m.en > en_lang.txt &\n",
        "!langid --line -n < subs_2m.pt > pt_lang.txt &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beOKLbf8BA-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src = course[:2]\n",
        "tgt = course[3:]\n",
        "src_idx = set()\n",
        "tgt_idx = set()\n",
        "src_langid = open(src+'_lang.txt').readlines()\n",
        "tgt_langid = open(tgt+'_lang.txt').readlines()\n",
        "for i in range(len(src_langid)):\n",
        "    line = src_langid[i].strip().split() \n",
        "    if line[0][2:4] == src and float(line[1][:-1]) > 0.7:\n",
        "        src_idx.add(i)\n",
        "    elif float(line[1][:-1])< 0.3:\n",
        "        src_idx.add(i)\n",
        "    line = tgt_langid[i].strip().split() \n",
        "    if line[0][2:4] == tgt and float(line[1][:-1]) > 0.7:\n",
        "        tgt_idx.add(i)\n",
        "    elif float(line[1][:-1])< 0.3:\n",
        "        tgt_idx.add(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ9neBCc1Hu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_lines = open('subs_2m.en').readlines()\n",
        "pt_lines = open('subs_2m.pt').readlines()\n",
        "src_idx = src_idx.intersection_update(tgt_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWGnDiPCc4-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with  open('subs_2m.pt', 'w') as pt, open('subs_2m.en', 'w') as en:\n",
        "    for i in range(len(en_lines)):\n",
        "        l1 = len(en_lines[i].strip().split())\n",
        "        l2 = len(pt_lines[i].strip().split())\n",
        "        if i in src_idx and  l1/l2 < 2 and l1/l2 > 0.5 :            \n",
        "            if en_lines[i][0] == '-':\n",
        "                en_lines_towrite = en_lines[i][2:]\n",
        "            else:\n",
        "                en_lines_towrite = en_lines[i]                                \n",
        "            if pt_lines[i][0] == '-':\n",
        "                pt_lines_towrite = pt_lines[i][2:]\n",
        "            else:\n",
        "                pt_lines_towrite = pt_lines[i]\n",
        "            if en_lines_towrite:\n",
        "                en.writelines(en_lines_towrite)\n",
        "                pt.writelines(pt_lines_towrite)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTorrclfQVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fd5071d4-6ee7-43b3-ea1a-38872b950421"
      },
      "source": [
        "!wc -l subs_2m.pt\n",
        "!wc -l subs_2m.en"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1116560 subs_2m_v2.pt\n",
            "1116560 subs_2m_v2.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEXoecENCX4k",
        "colab_type": "text"
      },
      "source": [
        "## 4. BPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU_UvpzPCFGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize\n",
        "cat $dir/output/corpus.$src.c.up.nor.up.nor.nonalpha.nonmatch.reptok.goodlang | $mosesdir/tokenizer/normalize-punctuation.perl -l $src | $mosesdir/tokenizer/tokenizer.perl -a -threads 8 -l $src > $dir/1-tok/corpus.tok.$src\n",
        "cat $dir/output/corpus.$trg.c.up.nor.up.nor.nonalpha.nonmatch.reptok.goodlang | $mosesdir/tokenizer/normalize-punctuation.perl -l $trg | $mosesdir/tokenizer/tokenizer.perl -a -threads 8 -l $trg > $dir/1-tok/corpus.tok.$trg\n",
        "\n",
        "# Clean\n",
        "$mosesdir/training/clean-corpus-n.perl $dir/1-tok/corpus.tok $src $trg $dir/2-clean/corpus.clean.tok 2 128\n",
        "\n",
        "# Train truecasers\n",
        "$mosesdir/recaser/train-truecaser.perl -corpus $dir/2-clean/corpus.clean.tok.$trg -model $dir/2-clean/truecase-model.$trg\n",
        "$mosesdir/recaser/train-truecaser.perl -corpus $dir/2-clean/corpus.clean.tok.$src -model $dir/2-clean/truecase-model.$src\n",
        "\n",
        "# Truecase\n",
        "$mosesdir/recaser/truecase.perl -model $dir/2-clean/truecase-model.$trg < $dir/2-clean/corpus.clean.tok.$trg > $dir/3-tc/corpus.tc.$trg\n",
        "$mosesdir/recaser/truecase.perl -model $dir/2-clean/truecase-model.$src < $dir/2-clean/corpus.clean.tok.$src > $dir/3-tc/corpus.tc.$src\n",
        "\n",
        "# Split into subword units\n",
        "cat $dir/3-tc/corpus.tc.$trg $dir/3-tc/corpus.tc.$src | subword-nmt learn-bpe -s $merge_ops > $dir/4-bpe/model.bpe\n",
        "\n",
        "subword-nmt apply-bpe -c $dir/4-bpe/model.bpe < $dir/3-tc/corpus.tc.$trg > $dir/4-bpe/corpus.bpe.$trg &\n",
        "subword-nmt apply-bpe -c $dir/4-bpe/model.bpe < $dir/3-tc/corpus.tc.$src > $dir/4-bpe/corpus.bpe.$src &\n",
        "\n",
        "wait"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}